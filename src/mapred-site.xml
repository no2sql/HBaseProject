<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!-- Autogenerated by Cloudera SCM on Thu Jan 12 14:25:21 EST 2012 -->

<configuration>
  
  <property>
    <name>mapred.job.tracker</name>
    <value>singapore.hadoop.local:8021</value>
  </property>

    <property>
      <name>io.sort.factor</name>
      <value>25</value>
      <description>The number of streams to merge at once while sorting files. This determines the number of open file handles.</description>
    </property>

    <property>
      <name>io.sort.record.percent</name>
      <value>0.05</value>
      <description>The percentage of io.sort.mb dedicated to tracking record boundaries. Let this value be r, io.sort.mb be x. The maximum number of records collected before the collection thread must block is equal to (r * x) / 4</description>
    </property>

    <property>
      <name>io.sort.spill.percent</name>
      <value>0.8</value>
      <description>The soft limit in either the buffer or record collection buffers. Once reached, a thread will begin to spill the contents to disk in the background. Note that this does not imply any chunking of data to the spill. A value less than 0.5 is not recommended.</description>
    </property>

    <property>
      <name>mapred.reduce.parallel.copies</name>
      <value>20</value>
      <description>The default number of parallel transfers run by reduce during the copy(shuffle) phase.</description>
    </property>

    <property>
      <name>io.sort.mb</name>
      <value>256</value>
      <description>The total amount of buffer memory to use while sorting files, in megabytes. By default, gives each merge stream 1MB, which should minimize seeks.</description>
    </property>


  <property>
    <name>mapred.reduce.tasks</name>
    <value>150</value>
    <description>The default number of reduce tasks per job. Ignored when mapred.job.tracker is "local".</description>
  </property>

  <property>
    <name>mapred.child.java.opts</name>
    <value>-XX+UseConcMarkSweetGC -Xmx1073741824</value>
    <description>Java opts for the task tracker child processes. The following symbol, if present, will be interpolated: @taskid@ is replaced by current TaskID. Any other occurrences of '@' will go unchanged. For example, to enable verbose gc logging to a file named for the taskid in /tmp and to set the heap maximum to be a gigabyte, pass a 'value' of: -Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc The configuration variable mapred.child.ulimit can be used to control the maximum virtual memory of the child processes.</description>
  </property>
    

  <property>
    <name>mapred.output.compress</name>
    <value>true</value>
    <description>Should the job outputs be compressed?</description>
  </property>

  <property>
    <name>mapred.output.compression.type</name>
    <value>BLOCK</value>
    <description>If the job outputs are to compressed as SequenceFiles, how should they be compressed? Should be one of NONE, RECORD or BLOCK.</description>
  </property>

  <property>
    <name>mapred.output.compression.codec</name>
    <value>org.apache.hadoop.io.compress.SnappyCodec</value>
    <description>If the job outputs are compressed, how should they be compressed?</description>
  </property>

  <property>
    <name>mapred.compress.map.output</name>
    <value>true</value>
    <description>If set to true, uses SequenceFile compression to compress the outputs of the maps before being sent across the network.</description>
  </property>

  <property>
    <name>mapred.map.output.compression.codec</name>
    <value>org.apache.hadoop.io.compress.SnappyCodec</value>
    <description>If the map outputs are compressed, how should they be compressed?
    </description>
  </property>

  <property>
    <name>mapred.job.reuse.jvm.num.tasks</name>
    <value>-1</value>
    <description>How many tasks to run per jvm. If set to -1, there is no limit.</description>
  </property>
  
  <property>
    <name>mapred.tasktracker.map.tasks.maximum</name>
    <value>4</value>    
  </property>
  
  <property>
    <name>mapreduce.task.timeout</name>
    <value>43200000</value>
  </property>
  
  <property>
    <name>mapreduce.reduce.shuffle.read.timeout</name>
    <value>43200000</value>
  </property>
  
  <property>
    <name>mapreduce.tasktracker.healthchecker.script.timeout</name>
    <value>43200000</value>
  </property>
  
  
  <property>
    <name>mapred.task.timeout</name>
    <value>43200000</value>
  </property>
  
  <property>
    <name>mapred.reduce.shuffle.read.timeout</name>
    <value>43200000</value>
  </property>
  
  <property>
    <name>mapred.tasktracker.healthchecker.script.timeout</name>
    <value>43200000</value>
  </property>
  
  <property>
    <name>mapreduce.client.submit.file.replication</name>
    <value>3</value>
  </property>
  
  <!-- 
  <property>
    <name>mapred.task.profile</name>
    <value>true</value>
  </property>
  <property>
    <name>mapred.task.profile.maps</name>
    <value>4</value>
  </property>
  <property>
    <name>mapred.task.profile.reduces</name>
    <value>4</value>
  </property>-->
  
</configuration>
